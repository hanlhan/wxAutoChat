<body class="typora-export">
# 模型评估

## 一、数据集切分

1. 数据集切分的通用参数：

    * `random_state`：一个整数或者一个`RandomState`实例，或者`None`，指定随机数种子。

        * 如果为整数，则它指定了随机数生成器的种子。
        * 如果为`RandomState`实例，则指定了随机数生成器。
        * 如果为`None`，则使用默认的随机数生成器。

    * `X`：样本集合。通常是一个`numpy array`，每行代表一个样本，每列代表一个特征。

    * `y`：样本的标签集合。它与`X` 的每一行相对应。

    * `groups`：样本的分组标记集合。它与`X` 的每一行相对应，用于训练集、测试集的拆分。



### 1.1 train_test_split

1. `train_test_split`用于将数据集切分成训练集和测试集，其原型为：

```
sklearn.model_selection.train_test_split(*arrays, **options)
```

返回值：一个列表，依次给出一个或者多个数据集的划分的结果。每个数据集都划分为两部分：训练集、测试集。

参数：

    * `*arrays`：一个或者多个数组，代表被拆分的一些数据集。

    * `test_size`：一个浮点数，整数或者`None`，指定测试集大小。

        * 浮点数：必须是0.0 到 1.0 之间的数，代表测试集占原始数据集的比例。
        * 整数：代表测试集大小。
        * `None`：如果训练集大小也指定为`None`，则`test_size`设为 0.25。

    * `train_size`：一个浮点数，整数或者`None`，指定训练集大小。

        * 浮点数：必须是0.0 到 1.0 之间的数，代表训练集占原始数据集的比例。
        * 整数：代表训练集大小。
        * `None`：如果测试集大小也指定为`None`，则`test_size`设为 0.75。

    * `random_state`：指定随机数种子。

    * `stratify`：一个数组对象或者`None`。如果它不是`None`，则原始数据会分层采样，采样的标记数组就由该参数指定。



### 1.2 KFold

1. `KFold`类实现了数据集的<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 521 858.4" width="1.21ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" id="E23-MJMATHI-6B" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E23-MJMATHI-6B" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-23" type="math/tex">k</script>折交叉切分。其原型为：

```
xxxxxxxxxxclass sklearn.model_selection.KFold(n_splits=3, shuffle=False, random_state=None)
```

    * `n_splits`：一个整数，即<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 521 858.4" width="1.21ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" id="E23-MJMATHI-6B" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E23-MJMATHI-6B" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-23" type="math/tex">k</script>（要求该整数值大于等于 2）。
    * `shuffle`：一个布尔值。如果为`True`，则在切分数据集之前先混洗数据集。
    * `random_state`：指定随机数种子。

2. 方法：

    * `get_n_splits([X, y, groups])` ：返回`n_splits`参数。

    参数：其参数都被忽略，用于保持接口的兼容性。

    * `split(X[, y, groups])`：切分数据集为训练集和测试集。返回测试集的样本索引、训练集的样本索引。

    参数：

        * `X`为训练数据集，形状为`(n_samples,n_features)`
        * `y`为标记信息，形状为`(n_samples,)`
        * `groups`：样本的分组标记，用于拆分。


3. `KFold`首先将 `0~(n-1)`之间的整数从前到后均匀划分成 `n_splits`份。每次迭代时依次挑选一份作为测试集样本的下标。

    * 如果`shuffle=True`， 则按顺序划分。
    * 如果`shuffle=False`， 则按随机划分。


### 1.3 StratifiedKFold

1. `StratifiedKFold`类实现了数据集的分层采样<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 521 858.4" width="1.21ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" id="E23-MJMATHI-6B" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E23-MJMATHI-6B" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-23" type="math/tex">k</script>折交叉切分。其原型为：

```
xxxxxxxxxxclass sklearn.model_selection.StratifiedKFold(n_splits=3, shuffle=False, random_state=None)
```

参数：参考`KFold` 。

2. 方法：参考`KFold` 。

3. `StratifiedKFold` 的用法类似于`KFold`，但是`StratifiedKFold`执行的是分层采样：保证训练集、测试集中各类别样本的比例与原始数据集中相同。


### 1.4 LeaveOneOut

1. `LeaveOneOut` 类实现了数据集的留一法拆分(简称`LOO`)。它是个生成器，其原型为：

```
xxxxxxxxxxclass sklearn.model_selection.LeaveOneOut(n)
```

    * `n`：一个整数，表示数据集大小。

2. `LeaveOneOut`的用法很简单。它每次迭代时，依次取 `0,1,...(n-1)` 作为测试集样本的下标。

```
xxxxxxxxxxfrom sklearn.model_selection import LeaveOneOutfor train_index,test_index in LeaveOneOut(len(y)):    #train_index 保存训练集样本下标，test_index 保存测试集样本下标
```


### 1.5 cross_val_score

1. 便利函数`cross_val_score` 对`estimator` 执行`k` 折交叉验证。其原型为：

```
xxxxxxxxxxsklearn.model_selection.cross_val_score(estimator, X, y=None, scoring=None, cv=None,n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')
```

返回值：返回一个浮点数的数组。每个浮点数都是针对某次<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 521 858.4" width="1.21ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" id="E23-MJMATHI-6B" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E23-MJMATHI-6B" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-23" type="math/tex">k</script>折交叉的数据集上， `estimator`预测性能得分。

参数：

    * `estimator`：指定的学习器，该学习器必须有`.fit`方法来进行训练。

    * `X`：样本集合。通常是一个`numpy array`，每行代表一个样本，每列代表一个特征。

    * `y`：样本的标签集合。它与`X` 的每一行相对应。

    * `groups`：样本的分组标记集合。它与`X` 的每一行相对应，用于训练集、测试集的拆分。

    * `scoring`：一个字符串，或者可调用对象，或者`None`，它指定了评分函数。

    如果为可调用对象，则参数为`estimator, X, y` ，返回值为一个浮点数表示预测能力得分。

    如果为`None`，则采用`estimator`学习器的`.score`方法。

    如果为字符串，则可以为下列字符串：

        * `'accuracy'`：采用的是`metrics.accuracy_score`评分函数。

        * `'average_precision'`：采用的是`metrics.average_precision_score`评分函数。

        * `f1`系列：采用的是`metrics.f1_score` 评分函数。包括：

            * `'f1'`：`f1` 值作为评分。用于二分类问题。
            * `'f1_micro'` ：微`f1` 值作为评分。用于多分类问题。
            * `'f1_macro'`：宏`f1` 值作为评分。用于多分类问题。
            * `'f1_weighted'`：加权 `f1` 值作为评分。
            * `'f1_samples'` ：多标签`f1` 值作为评分。

        * `'log_loss'`： 采用的是`metrics.log_loss`评分函数。

        * `precision`系列：采用的是`metrics.precision_score`评分函数。

        具体形式类似`f1`系列。

        * `recall` 系列：采用的是`metrics.recall_score`评分函数。

        具体形式类似`f1`系列。

        * `'roc_auc'`：采用的是`metrics.roc_auc_score` 评分函数 。

        * `'adjusted_rand_score'`：采用的是`metrics.adjusted_rand_score` 评分函数。

        * `'mean_absolute_error'`：采用的是`metrics.mean_absolute_error` 评分函数。

        * `'mean_squared_error’'`：采用的是`metrics.mean_squared_error` 评分函数。

        * `'median_absolute_error'`：采用的是`metrics.median_absolute_error` 评分函数。

        * `'r2'`：采用的是`metrics.r2_score` 评分函数 。


    * `cv`：一个整数、<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 521 858.4" width="1.21ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" id="E23-MJMATHI-6B" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E23-MJMATHI-6B" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-23" type="math/tex">k</script>折交叉生成器、一个迭代器、或者`None`，指定`k` 折交叉参数。

        * 如果为`None`，则使用默认的 3 折交叉生成器。
        * 如果为整数，则指定了<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 521 858.4" width="1.21ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" id="E23-MJMATHI-6B" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E23-MJMATHI-6B" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-23" type="math/tex">k</script>折交叉生成器的<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 521 858.4" width="1.21ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" id="E23-MJMATHI-6B" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E23-MJMATHI-6B" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-23" type="math/tex">k</script>值。
        * 如果为<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 521 858.4" width="1.21ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" id="E23-MJMATHI-6B" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E23-MJMATHI-6B" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-23" type="math/tex">k</script>折交叉生成器，则直接指定了<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 521 858.4" width="1.21ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" id="E23-MJMATHI-6B" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E23-MJMATHI-6B" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-23" type="math/tex">k</script>折交叉生成器。
        * 如果为迭代器，则迭代器的结果就是数据集划分的结果。

    * `fit_params`：一个字典，指定了`estimator`执行`.fit`方法时的关键字参数。

    * `n_jobs`：一个整数，指定并行性。

    * `verbose`：一个整数，用于控制输出日志。

    * `pre_dispatch`：一个整数或者字符串或者`None`，用于控制并行执行时，分发的总的任务数量。

        * 如果为`None`，则所有的`job` 立即创建并派生。
        * 如果为整数，则它指定了立即派生的`job` 的数量。
        * 如果为字符串，则指定了`n_jobs` 的表达式。如`'2*n_jobs'` 表示立即派生2倍 `n_jobs` 数量的`job` 。


2. 之所以称`cross_val_score` 为便利函数，是因为完全可以凭借现有的函数手动完成这个功能，步骤为：<br></br>

    * <span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 521 858.4" width="1.21ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" id="E23-MJMATHI-6B" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E23-MJMATHI-6B" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-23" type="math/tex">k</script>折交叉划分数据集，对每次划分结果执行：

        * 在训练集上训练 `estimator` 。
        * 用训练好的 `estimator` 预测测试集，返回测试性能得分。

    * 收集所有的测试性能得分，放入一个数组并返回。





## 二、性能度量

1. 在`scikit-learn`中有三种方法来评估`estimator` 的预测性能：

    * `estimator` 的`.score`方法。
    * 通过使用`model_selection`中的模型评估工具来评估，如`model_selection.cross_val_score`等方法。
    * 通过`scikit-learn`的`metrics`模块中的函数来评估`estimator` 的预测性能。这里重点讲解这些函数。

2. `metrics`模块中的性能评价函数的通用参数：

    * `y_true`：一个数组，给出了真实的标记集合。
    * `y_pred`：一个数组，给出了预测的标记集合。
    * `sample_weight`：一个浮点数，给出了样本权重。默认每个样本的权重为 1。


### 2.1 分类问题性能度量

#### 2.1.1 accuracy_score

1. `accuracy_score`函数用于计算分类结果的准确率，其原型为：

```
xxxxxxxxxxsklearn.metrics.accuracy_score(y_true, y_pred, normalize=True, sample_weight=None)
```

返回值：如果`normalize`为`True`，则返回准确率；如果`normalize`为`False`，则返回正确分类的数量。

参数：

    * `y_true`：真实的标记集合。

    * `y_pred`：预测的标记集合。

    * `normalize`：一个布尔值，指示是否需要归一化结果。

        * 如果为`True`，则返回分类正确的比例（准确率）。
        * 如果为`False`，则返回分类正确的样本数量。

    * `sample_weight`：样本权重，默认每个样本的权重为 1 。



#### 2.1.2 precision_score

1. `precision_score`函数用于计算分类结果的查准率，其原型为：

```
xxxxxxxxxxsklearn.metrics.precision_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)
```

返回值：查准率。即预测结果为正类的那些样本中，有多少比例确实是正类。

参数：

    * `y_true`：真实的标记集合。

    * `y_pred`：预测的标记集合。

    * `labels`：一个列表。当`average` 不是`'binary'` 时使用。

        * 对于多分类问题，它指示：将计算哪些类别。不在`labels` 中的类别，计算`macro precision` 时其成分为 0 。
        * 对于多标签问题，它指示待考察的标签的索引。
        * 除了`average=None` 之外，`labels` 的元素的顺序也非常重要。
        * 默认情况下，`y_true` 和 `y_pred` 中所有的类别都将被用到。

    * `pos_label`：一个字符串或者整数，指定哪个标记值属于正类。

        * 如果是多分类或者多标签问题，则该参数被忽略。
        * 如果设置`label=[pos_label]` 以及`average!='binary'` 则会仅仅计算该类别的`precision` 。

    * `average`：一个字符串或者`None`，用于指定二分类或者多类分类的`precision` 如何计算。

        * `'binary'`：计算二类分类的`precision`。 此时由`pos_label` 指定的类为正类，报告其`precision` 。

        它要求`y_true、y_pred` 的元素都是`0,1` 。

        * `'micro'`：通过全局的正类和父类，计算`precision` 。

        * `'macro'`：计算每个类别的`precision`，然后返回它们的均值。

        * `'weighted'`：计算每个类别的`precision`，然后返回其加权均值，权重为每个类别的样本数。

        * `'samples'`：计算每个样本的`precision`，然后返回其均值。

        该方法仅仅对于多标签分类问题有意义。

        * `None`：计算每个类别的`precision`，然后以数组的形式返回每个`precision` 。


    * `sample_weight`：样本权重，默认每个样本的权重为 1



#### 2.1.3 recall_score

1. `recall_score`函数用于计算分类结果的查全率，其原型为：

```
xxxxxxxxxxsklearn.metrics.recall_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)
```

返回值：查全率。即真实的正类中，有多少比例被预测为正类。

参数：参考`precision_score` 。


#### 2.1.4 f1_score

1. `f1_score`函数用于计算分类结果的<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-16-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="2.227ex" role="img" style="vertical-align: -0.472ex;" viewbox="0 -755.9 1096.6 958.9" width="2.547ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z" id="E16-MJMATHI-46" stroke-width="0"></path><path d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" id="E16-MJMAIN-31" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E16-MJMATHI-46" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use><use transform="scale(0.707)" x="909" xlink:href="#E16-MJMAIN-31" xmlns:xlink="http://www.w3.org/1999/xlink" y="-213"></use></g></svg></span><script id="MathJax-Element-16" type="math/tex">F_1</script>值，其原型为：

```
xxxxxxxxxxsklearn.metrics.f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)
```

返回值：<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-16-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="2.227ex" role="img" style="vertical-align: -0.472ex;" viewbox="0 -755.9 1096.6 958.9" width="2.547ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z" id="E16-MJMATHI-46" stroke-width="0"></path><path d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" id="E16-MJMAIN-31" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E16-MJMATHI-46" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use><use transform="scale(0.707)" x="909" xlink:href="#E16-MJMAIN-31" xmlns:xlink="http://www.w3.org/1999/xlink" y="-213"></use></g></svg></span><script id="MathJax-Element-16" type="math/tex">F_1</script>值。即查准率和查全率的调和均值。

参数：参考`precision_score` 。


#### 2.1.5 fbeta_score

1. `fbeta_score`函数用于计算分类结果的<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-14-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="2.577ex" role="img" style="vertical-align: -0.822ex;" viewbox="0 -755.9 1148.2 1109.7" width="2.667ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z" id="E14-MJMATHI-46" stroke-width="0"></path><path d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z" id="E14-MJMATHI-3B2" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E14-MJMATHI-46" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use><use transform="scale(0.707)" x="909" xlink:href="#E14-MJMATHI-3B2" xmlns:xlink="http://www.w3.org/1999/xlink" y="-218"></use></g></svg></span><script id="MathJax-Element-14" type="math/tex">F_\beta</script>值，其原型为：

```
xxxxxxxxxxsklearn.metrics.fbeta_score(y_true, y_pred, beta, labels=None, pos_label=1, average='binary', sample_weight=None)
```

返回值：<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-14-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="2.577ex" role="img" style="vertical-align: -0.822ex;" viewbox="0 -755.9 1148.2 1109.7" width="2.667ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z" id="E14-MJMATHI-46" stroke-width="0"></path><path d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z" id="E14-MJMATHI-3B2" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E14-MJMATHI-46" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use><use transform="scale(0.707)" x="909" xlink:href="#E14-MJMATHI-3B2" xmlns:xlink="http://www.w3.org/1999/xlink" y="-218"></use></g></svg></span><script id="MathJax-Element-14" type="math/tex">F_\beta</script>值。

参数：

    * `beta`：<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-15-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="2.461ex" role="img" style="vertical-align: -0.588ex;" viewbox="0 -806.1 573 1059.4" width="1.331ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z" id="E15-MJMATHI-3B2" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E15-MJMATHI-3B2" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-15" type="math/tex">\beta</script>值
    * 其它参数参考`precision_score` 。


#### 2.1.6 classification_report

1. `classification_report`函数以文本方式给出了分类结果的主要预测性能指标。其原型为：

```
xxxxxxxxxxsklearn.metrics.classification_report(y_true, y_pred, labels=None, target_names=None,sample_weight=None, digits=2)
```

返回值：一个格式化的字符串，给出了分类评估报告。

参数：

    * `y_true`：真实的标记集合。
    * `y_pred`：预测的标记集合。
    * `labels`：一个列表，指定报告中出现哪些类别。
    * `target_names`：一个列表，指定报告中类别对应的显示出来的名字。
    * `digits`：用于格式化报告中的浮点数，保留几位小数。
    * `sample_weight`：样本权重，默认每个样本的权重为 1

2. 分类评估报告的内容如下，其中：

    * `precision`列：给出了查准率。它依次将类别 0 作为正类，类别 1 作为正类...

    * `recall`列：给出了查全率。它依次将类别 0 作为正类，类别 1 作为正类...

    * `recall`列：给出了<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-16-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="2.227ex" role="img" style="vertical-align: -0.472ex;" viewbox="0 -755.9 1096.6 958.9" width="2.547ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z" id="E16-MJMATHI-46" stroke-width="0"></path><path d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" id="E16-MJMAIN-31" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E16-MJMATHI-46" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use><use transform="scale(0.707)" x="909" xlink:href="#E16-MJMAIN-31" xmlns:xlink="http://www.w3.org/1999/xlink" y="-213"></use></g></svg></span><script id="MathJax-Element-16" type="math/tex">F_1</script>值。

    * `support`列：给出了该类有多少个样本。

    * `avg / total`行：

        * 对于`precision,recall,recall`，给出了该列数据的算术平均。
        * 对于`support`列，给出了该列的算术和（其实就等于样本集总样本数量）。


```
xxxxxxxxxxClassification Report:precision    recall  f1-score   supportclass_0       0.62      1.00      0.77         5class_1       1.00      0.40      0.57         5avg / total       0.81      0.70      0.67        10
```


#### 2.1.7 confusion_matrix

1. `confusion_matrix`函数给出了分类结果的混淆矩阵。其原型为：

```
xxxxxxxxxxsklearn.metrics.confusion_matrix(y_true, y_pred, labels=None)
```

返回值：一个格式化的字符串，给出了分类结果的混淆矩阵。

参数：参考`classification_report` 。

2. 混淆矩阵的内容如下，其中<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-17-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="2.694ex" role="img" style="vertical-align: -0.822ex;" viewbox="0 -806.1 1546.9 1160" width="3.593ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z" id="E17-MJMATHI-43" stroke-width="0"></path><path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" id="E17-MJMATHI-69" stroke-width="0"></path><path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" id="E17-MJMAIN-2C" stroke-width="0"></path><path d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" id="E17-MJMATHI-6A" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E17-MJMATHI-43" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use><g transform="translate(715,-150)"><use transform="scale(0.707)" x="0" xlink:href="#E17-MJMATHI-69" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use><use transform="scale(0.707)" x="345" xlink:href="#E17-MJMAIN-2C" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use><use transform="scale(0.707)" x="623" xlink:href="#E17-MJMATHI-6A" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></g></svg></span><script id="MathJax-Element-17" type="math/tex">C_{i,j}</script>表示真实标记为<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-18-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 345 858.4" width="0.801ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" id="E18-MJMATHI-69" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E18-MJMATHI-69" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-18" type="math/tex">i</script>但是预测为<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-19-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="2.461ex" role="img" style="vertical-align: -0.705ex; margin-left: -0.028ex;" viewbox="-12 -755.9 424 1059.4" width="0.985ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" id="E19-MJMATHI-6A" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E19-MJMATHI-6A" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-19" type="math/tex">j</script>的样本的数量。

```
xxxxxxxxxxConfusion Matrix:[[5 0][3 2]]
```


#### 2.1.8 precision_recall_curve

1. `precision_recall_curve`函数用于计算分类结果的`P-R`曲线。其原型为：

```
xxxxxxxxxxsklearn.metrics.precision_recall_curve(y_true, probas_pred, pos_label=None,sample_weight=None)
```

返回值：一个元组，元组内的元素分别为：

    * `P-R`曲线的查准率序列。该序列是递增序列，序列第 `i` 个元素是当正类概率的判定阈值为 `thresholds[i]`时的查准率。
    * `P-R`曲线的查全率序列。该序列是递减序列，序列第 `i` 个元素是当正类概率的判定阈值为 `thresholds[i]`时的查全率。
    * `P-R`曲线的阈值序列`thresholds`。该序列是一个递增序列，给出了判定为正例时的正类概率的阈值。

参数：

    * `y_true`：真实的标记集合。
    * `probas_pred`：每个样本预测为正类的概率的集合。
    * `pos_label`：正类的类别标记。
    * `sample_weight`：样本权重，默认每个样本的权重为 1。


#### 2.1.9 roc_curve

1. `roc_curve`函数用于计算分类结果的`ROC`曲线。其原型为：

```
xxxxxxxxxxsklearn.metrics.roc_curve(y_true, y_score, pos_label=None, sample_weight=None,drop_intermediate=True)
```

返回值：一个元组，元组内的元素分别为：

    * `ROC`曲线的<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-20-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 2259 858.4" width="5.247ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z" id="E20-MJMATHI-46" stroke-width="0"></path><path d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" id="E20-MJMATHI-50" stroke-width="0"></path><path d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z" id="E20-MJMATHI-52" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E20-MJMATHI-46" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use><use x="749" xlink:href="#E20-MJMATHI-50" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use><use x="1500" xlink:href="#E20-MJMATHI-52" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-20" type="math/tex">FPR</script>序列。该序列是递增序列，序列第 `i` 个元素是当正类概率的判定阈值为 `thresholds[i]`时的假正例率。
    * `ROC`曲线的<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-21-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 2214 858.4" width="5.142ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z" id="E21-MJMATHI-54" stroke-width="0"></path><path d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" id="E21-MJMATHI-50" stroke-width="0"></path><path d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z" id="E21-MJMATHI-52" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E21-MJMATHI-54" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use><use x="704" xlink:href="#E21-MJMATHI-50" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use><use x="1455" xlink:href="#E21-MJMATHI-52" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-21" type="math/tex">TPR</script>序列。该序列是递增序列，序列第 `i` 个元素是当正类概率的判定阈值为 `thresholds[i]`时的真正例率。
    * `ROC`曲线的阈值序列`thresholds`。该序列是一个递减序列，给出了判定为正例时的正类概率的阈值。

参数：

    * `y_true`：真实的标记集合。
    * `y_score`：每个样本预测为正类的概率的集合。
    * `pos_label`：正类的类别标记。
    * `sample_weight`：样本权重，默认每个样本的权重为 1。
    * `drop_intermediate`：一个布尔值。如果为`True`，则抛弃某些不可能出现在`ROC`曲线上的阈值。


#### 2.1.10 roc_auc_score

1. `roc_auc_score`函数用于计算分类结果的`ROC`曲线的面积`AUC`。其原型为：

```
xxxxxxxxxxsklearn.metrics.roc_auc_score(y_true, y_score, average='macro', sample_weight=None)
```

返回值：`AUC`值。

参数：参考 `roc_curve` 。


### 2.2 回归问题性能度量

#### 2.2.1 mean_absolute_error

1. `mean_absolute_error`函数用于计算回归预测误差绝对值的均值(`mean absolute error:MAE`)，其原型为：

```
xxxxxxxxxxsklearn.metrics.mean_absolute_error(y_true, y_pred, sample_weight=None,multioutput='uniform_average')
```

返回值：预测误差绝对值的均值。

参数：

    * `y_true`：真实的标记集合。

    * `y_pred`：预测的标记集合。

    * `multioutput`：指定对于多输出变量的回归问题的误差类型。可以为：

        * `'raw_values'`：对每个输出变量，计算其误差 。
        * `'uniform_average'`：计算其所有输出变量的误差的平均值。

    * `sample_weight`：样本权重，默认每个样本的权重为 1。



#### 2.2.2 mean_squared_error

1. `mean_squared_error`函数用于计算回归预测误差平方的均值(`mean square error:MSE`)，其原型为：

```
xxxxxxxxxxsklearn.metrics.mean_squared_error(y_true, y_pred, sample_weight=None,multioutput='uniform_average')
```

返回值：预测误差的平方的平均值。

参数：参考`mean_absolute_error` 。


## 三、验证曲线 && 学习曲线

### 3.1 验证曲线

1. 验证曲线给出了`estimator` 因为某个超参数的不同取值在同一个测试集上预测性能曲线。

它的作用是执行超参数调优。

2. `validation_curve` 用于生成验证曲线，其原型为：

```
xxxxxxxxxxsklearn.model_selection.validation_curve(estimator, X, y, param_name, param_range, cv=None, scoring=None, n_jobs=1, pre_dispatch='all', verbose=0)
```

返回值：返回一个元组，其元素依次为：

    * `train_scores`：学习器在训练集上的预测得分的序列（针对不同的参数值），是个二维数组。
    * `test_scores`：学习器在测试集上的预测得分的序列（针对不同的参数值），是个二维数组。

> > 

> 因为对于每个固定的参数值，<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 521 858.4" width="1.21ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" id="E23-MJMATHI-6B" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E23-MJMATHI-6B" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-23" type="math/tex">k</script>折交叉会产生多个测试集，得到多个测试得分。



参数：

    * `estimator`：一个学习器对象。它必须有`.fit`方法用于学习，`.predict`方法用于预测。
    * `param_name`：一个字符串，指定了学习器需要变化的参数。
    * `param_range`：一个序列，指定了`param_name`指定的参数的取值范围。
    * 其它参数参考`cross_val_score` 。


### 3.2 学习曲线

1. 学习曲线给出了`estimator` 因为数据集大小的不同而导致的学习器在训练集和测试集上预测性能曲线。

其作用是评估样本集大小的变化对学习器的性能的影响。

2. `learning_curve`函数用于生成学习曲线，其原型为：

```
xxxxxxxxxxsklearn.model_selection.learning_curve(estimator, X, y, train_sizes=array([ 0.1, 0.33, 0.55, 0.78, 1. ]), cv=None,scoring=None, exploit_incremental_learning=False,n_jobs=1, pre_dispatch='all', verbose=0)
```

返回值：返回一个元组，其元素依次为：

    * `train_sizes_abs`：考察数据集大小组成的序列。
    * `train_scores`：学习器在训练集上的预测得分的序列（针对不同的考察数据集），是个二维数组。
    * `test_scores`：学习器在测试集上的预测得分的序列（针对不同的考察数据集），是个二维数组。

参数：

    * `train_sizes`：一个数组，给出了训练集的大小。

        * 如果元素为整数，则表示每个训练集的绝对大小。
        * 如果元素为浮点数，则表示每个训练集的相对大小。

    * `exploit_incremental_learning`：一个布尔值。如果`estimator` 支持增量学习，那么设置它为`True` 。

    此时该函数会使用增量学习来加速学习曲线的生成过程。

    * 其它参数参考`validation_curve` 。



## 四、超参数优化

### 4.1 GridSearchCV

1. `GridSearchCV`用于实现超参数优化，其原型为：

```
xxxxxxxxxxclass sklearn.model_selection.GridSearchCV(estimator, param_grid, scoring=None,fit_params=None, n_jobs=1, iid=True, refit=True, cv=None,verbose=0,pre_dispatch='2*n_jobs', error_score='raise',return_train_score='warn')
```

    * `estimator`：一个学习器对象。它必须有`.fit`方法用于学习，`.predict`方法用于预测，有`.score`方法用于性能评分。

    * `param_grid`：字典或者字典的列表。每个字典都给出了学习器的一个超参数，其中：

        * 字典的键就是超参数名。
        * 字典的值是一个列表，指定了超参数对应的候选值序列。

    * `fit_params`：一个字典，用来给学习器的`.fit`方法传递参数。

    * `iid`：如果为`True`，则表示数据是独立同分布的。

    * `refit`：一个布尔值。如果为`True`，则在参数优化之后使用整个数据集来重新训练该最优的`estimator` 。

    * `error_score`：一个数值或者字符串`'raise'`，指定当`estimator`训练发生异常时，如何处理：

        * 如果为`'raise'`，则抛出异常。
        * 如果为数值，则将该数值作为本轮`estimator`的预测得分。

    * `return_train_score`： 一个布尔值，指示是否返回训练集的预测得分。

    如果为`'warn'`，则等价于`True` 并抛出一个警告。

    * 其它参数参考`cross_val_score` 。


2. 属性：

    * `cv_results_`：一个数组的字典。可以直接用于生成`pandas DataFrame` 。其中键为超参数名，值为超参数的数组。

    另外额外多了一些键：

        * `mean_fit_time`、`mean_score_time` 、`std_fit_time`、`std_score_time`：给出了训练时间、评估时间的均值和方差，单位为秒。
        * `xx_score`：给出了各种评估得分。

    * `best_estimator_`：一个学习器对象，代表了根据候选参数组合筛选出来的最佳的学习器。

    如果`refit=False`，则该属性不可用。

    * `best_score_`：最佳学习器的性能评分。

    * `best_params_`：最佳参数组合。

    * `best_index_`：`cv_results_`中，第几组参数对应着最佳参数组合。

    * `scorer_`：评分函数。

    * `n_splits_`：交叉验证的 `k` 值。


3. 方法：

    * `fit(X[, y,groups])`：执行参数优化。
    * `predict(X)` ：使用学到的最佳学习器来预测数据。
    * `predict_log_proba(X)` ：使用学到的最佳学习器来预测数据为各类别的概率的对数值。
    * `predict_proba(X)` ：使用学到的最佳学习器来预测数据为各类别的概率。
    * `score(X[, y])` ：通过给定的数据集来判断学到的最佳学习器的预测性能。
    * `transform(X)`：对最佳学习器执行`transform` 。
    * `inverse_transform(X)`：对最佳学习器执行逆 `transform` 。
    * `decision_function(X)`：对最佳学习器调用决策函数。

4. `GridSearchCV`实现了`estimator`的`.fit`、`.score`方法。这些方法内部会调用`estimator`的对应的方法。

在调用`GridSearchCV.fit`方法时，首先会将训练集进行<span class="MathJax_Preview"></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" style="font-size: 100%; display: inline-block;" tabindex="-1"><svg focusable="false" height="1.994ex" role="img" style="vertical-align: -0.238ex;" viewbox="0 -755.9 521 858.4" width="1.21ex" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" id="E23-MJMATHI-6B" stroke-width="0"></path></defs><g fill="currentColor" stroke="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use x="0" xlink:href="#E23-MJMATHI-6B" xmlns:xlink="http://www.w3.org/1999/xlink" y="0"></use></g></svg></span><script id="MathJax-Element-23" type="math/tex">k</script>折交叉，然后在每次划分的集合上进行多轮的训练和验证（每一轮都采用一种参数组合），然后调用最佳学习器的`.fit` 方法。


### 4.2 RandomizedSearchCV

1. `GridSearchCV`采用的是暴力寻找的方法来寻找最优参数。当待优化的参数是离散的取值的时候，`GridSearchCV`能够顺利找出最优的参数。但是当待优化的参数是连续取值的时候，暴力寻找就有心无力。

`GridSearchCV`的做法是从这些连续值中挑选几个值作为代表，从而在这些代表中挑选出最佳的参数。

2. `RandomizedSearchCV`采用随机搜索所有的候选参数对的方法来寻找最优的参数组合。其原型为：

```
xxxxxxxxxxclass sklearn.model_selection.RandomizedSearchCV(estimator, param_distributions,n_iter=10, scoring=None, fit_params=None, n_jobs=1, iid=True, refit=True,cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score='raise',return_train_score='warn')
```

    * `param_distributions`：字典或者字典的列表。每个字典都给出了学习器的一个参数，其中：

        * 字典的键就是参数名。

        * 字典的值是一个分布类，分布类必须提供`.rvs`方法。

        通常你可以使用`scipy.stats`模块中提供的分布类，比如`scipy.expon`(指数分布)、`scipy.gamma`(gamma分布)、`scipy.uniform`(均匀分布)、`randint`等等。

        * 字典的值也可以是一个数值序列，此时就在该序列中均匀采样。


    * `n_iter`：一个整数，指定每个参数采样的数量。通常该值越大，参数优化的效果越好。但是参数越大，运行时间也更长。

    * 其它参数参考`GridSearchCV` 。


3. 属性：参考`GridSearchCV` 。

4. 方法：参考`GridSearchCV` 。

<br></br>

</body>